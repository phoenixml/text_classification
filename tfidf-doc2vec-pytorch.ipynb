{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom category_encoders.one_hot import OneHotEncoder\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\nfrom torch.nn import Module\nfrom torch.nn import Linear\nfrom torch.nn import Sigmoid\n\nfrom torch.nn import MSELoss\nfrom torch.optim import Adam\n\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nfrom scipy.stats import spearmanr\nimport gc\n\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\nfrom gensim.test.utils import common_texts\nfrom nltk.tokenize import word_tokenize","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ntrain = pd.read_csv(\"/kaggle/input/google-quest-challenge/train.csv\")\ntexts = list(train['answer'].values)\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDoc2Vec():\n    def __init__(self):\n        self.tadded_data = None\n        self.model = None\n        \n    def fit_transform(self, df):\n        texts = list(df.values)\n        tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(texts)]\n        self.model = Doc2Vec(tagged_data, vector_size=20, epochs=30)\n        feature = np.array([self.model.docvecs[i] for i in range(df.shape[0])]) # convert type docvecs to ndarray\n        return feature\n        \n    def transform(self, df):\n        texts = list(df.values)\n        words = [word_tokenize(texts[i].lower()) for i in range(df.shape[0])]\n        feature = np.array([self.model.infer_vector(words[i], epochs=30) for i in range(df.shape[0])])\n        return feature","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nmy_doc2vec = MyDoc2Vec()\nfeature = my_doc2vec.fit_transform(train['answer'])\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ntest_feature = my_doc2vec.transform(train['answer'])\ntest_feature2 = my_doc2vec.transform(train['answer'])\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cos_sim(v1, v2):\n    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cos_sim(test_feature2[0], test_feature[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing\nuse TFIDF and one-hot-encoder.","metadata":{}},{"cell_type":"code","source":"def load():\n    train = pd.read_csv(\"/kaggle/input/google-quest-challenge/train.csv\")\n    test = pd.read_csv(\"/kaggle/input/google-quest-challenge/test.csv\")\n    \n    target_cols = ['question_asker_intent_understanding',\n                   'question_body_critical', 'question_conversational',\n                   'question_expect_short_answer', 'question_fact_seeking',\n                   'question_has_commonly_accepted_answer',\n                   'question_interestingness_others', 'question_interestingness_self',\n                   'question_multi_intent', 'question_not_really_a_question',\n                   'question_opinion_seeking', 'question_type_choice',\n                   'question_type_compare', 'question_type_consequence',\n                   'question_type_definition', 'question_type_entity',\n                   'question_type_instructions', 'question_type_procedure',\n                   'question_type_reason_explanation', 'question_type_spelling',\n                   'question_well_written', 'answer_helpful',\n                   'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n                   'answer_satisfaction', 'answer_type_instructions',\n                   'answer_type_procedure', 'answer_type_reason_explanation',\n                   'answer_well_written']\n    \n    data_cols = ['question_title', 'question_body', 'answer', 'category']\n    \n    y_train = train[target_cols].copy()\n    print(type(y_train))\n    x_train = train[data_cols].copy()\n    del train\n\n    x_test = test.copy()\n    del test    \n\n    \n    question_body_doc2vec = MyDoc2Vec()\n    answer_doc3vec = MyDoc2Vec()\n    \n    x_train_question_vec = question_body_doc2vec.fit_transform(x_train['question_body'])\n    x_test_question_vec = question_body_doc2vec.transform(x_test['question_body'])\n    x_train_answer_vec = question_body_doc2vec.fit_transform(x_train['answer'])\n    x_test_answer_vec = question_body_doc2vec.transform(x_test['answer'])\n    \n    print(x_train_question_vec.shape)\n    \n    text_encoder = Pipeline([\n        ('Text-TF-IDF', TfidfVectorizer(ngram_range=(1, 1))),\n        ('Text-SVD', TruncatedSVD(n_components = 100))], verbose=True)\n    \n    ohe = OneHotEncoder(cols=['category'])\n    \n    preprocessor = ColumnTransformer([\n        ('Q-T', text_encoder, 'question_title'),\n        ('Q-B', text_encoder, 'question_body'),\n        ('A', text_encoder, 'answer'),\n        ('Category', ohe, 'category'),\n        ])\n    \n    x_train = preprocessor.fit_transform(x_train).astype(np.float32)\n    x_test = preprocessor.transform(x_test).astype(np.float32)\n    y_train = y_train.values.astype(np.float32)\n    \n    x_train = np.concatenate([x_train, x_train_question_vec, x_train_answer_vec], axis=1)\n    x_test = np.concatenate([x_test, x_test_question_vec, x_test_answer_vec], axis=1)\n    \n    return x_train, y_train, x_test\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_score(prediction, label):\n\n    score = 0\n    for col_index in range(30):\n        score += spearmanr(prediction[:, col_index], label[col_index]).correlation/len(target_cols)\n    return score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## NN Model","metadata":{}},{"cell_type":"code","source":"class Net(Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.hidden_feature = 600\n        self.linear1 = Linear(345, self.hidden_feature)\n        self.sigmoid1 = Sigmoid()\n        self.linear2 = Linear(self.hidden_feature, 30)\n        # self.sigmoid2 = Sigmoid()\n\n    def forward(self, x):\n        x = self.linear1(x)\n        x = self.sigmoid1(x)\n        x = self.linear2(x)\n        # x = self.sigmoid2(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n\n    def __init__(self, data, label, device, transform=None):\n        self.transform = transform\n        self.data = torch.from_numpy(data).to(device)\n        self.label = torch.from_numpy(label).to(device)\n        self.data_num = self.data.shape[0]\n        \n    def __len__(self):\n        return self.data_num\n\n    def __getitem__(self, idx):\n        out_data = self.data[idx]\n        out_label =  self.label[idx]\n\n        #if self.transform:\n        #    out_data = self.transform(out_data)\n\n        return out_data, out_label\n\n    def get_numpy_label(self):\n        return self.label.detach().cpu().numpy()\n    \nclass TestDataset(Dataset):\n\n    def __init__(self, data, device, transform=None):\n        self.transform = transform\n        self.data = torch.from_numpy(data).to(device)\n        self.data_num = self.data.shape[0]\n\n    def __len__(self):\n        return self.data_num\n\n    def __getitem__(self, idx):\n        out_data = self.data[idx]\n\n        #if self.transform:\n        #    out_data = self.transform(out_data)\n\n        return out_data\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"if torch.cuda.is_available():\n   device = 'cuda'\nelse:\n    device = 'cpu'\n\n\ntrain_data, train_label, test_data = load()\ndataset = MyDataset(train_data, train_label, device)\ntest_dataset = TestDataset(test_data, device)\ntrain_size = int(len(dataset)*1.0)\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n\nmodel = Net().to(device)\n\n\nepoch_size = 100\n\ncriterion = MSELoss()\noptimizer = Adam(model.parameters(), lr=1e-5)\n\nloss_list = np.zeros(epoch_size)\n\nfor epoch in range(epoch_size):\n    for n_batch, data_batched in enumerate(train_dataloader):\n        data, label = data_batched\n        optimizer.zero_grad()\n\n        output = model(data)\n        loss = criterion(output, label)\n        loss.backward()\n        optimizer.step()\n        tmp = loss.detach().cpu()\n        \n        loss_list[epoch] += tmp.detach().numpy()\n\n    loss_list[epoch] /= n_batch\n    print(f\"{epoch}, loss is {loss_list[epoch]}\")\n    \n# torch.save(model.state_dict(), 'weight.pth')\nplt.plot(loss_list)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validation","metadata":{}},{"cell_type":"code","source":"target_cols = ['question_asker_intent_understanding',\n               'question_body_critical', 'question_conversational',\n               'question_expect_short_answer', 'question_fact_seeking',\n               'question_has_commonly_accepted_answer',\n               'question_interestingness_others', 'question_interestingness_self',\n               'question_multi_intent', 'question_not_really_a_question',\n               'question_opinion_seeking', 'question_type_choice',\n               'question_type_compare', 'question_type_consequence',\n               'question_type_definition', 'question_type_entity',\n               'question_type_instructions', 'question_type_procedure',\n               'question_type_reason_explanation', 'question_type_spelling',\n               'question_well_written', 'answer_helpful',\n               'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n               'answer_satisfaction', 'answer_type_instructions',\n               'answer_type_procedure', 'answer_type_reason_explanation',\n               'answer_well_written']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_prediction = np.zeros((len(train_dataset), 30))\nmodel.eval()\nwith torch.no_grad():\n    for i, data in enumerate(train_dataset):\n        input, label = data\n        output = model(input)\n        train_prediction[i] = output.detach().cpu().numpy()\n        \ntrain_prediction = train_prediction.T\nprint(f\"training score is {calc_score(train_prediction, train_dataset.dataset.get_numpy_label())}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if len(val_dataset) != 0:\n    val_prediction = np.zeros((len(val_dataset), 30))\n    model.eval()\n    with torch.no_grad():\n        for i, data in enumerate(val_dataset):\n            input, label = data\n            output = model(input)\n            val_prediction[i] = output.detach().cpu().numpy()\n        \n    val_prediction = val_prediction.T\n    print(f\"validation score is {calc_score(val_prediction, val_dataset.dataset.get_numpy_label())}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"code","source":"prediction = np.zeros((len(test_dataset), 30))\nmodel.eval()\nwith torch.no_grad():\n    for i, data in enumerate(test_dataset):\n        output = model(data)\n        prediction[i] = output.detach().cpu().numpy()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submissin","metadata":{}},{"cell_type":"code","source":"sample = pd.read_csv(\"/kaggle/input/google-quest-challenge/sample_submission.csv\")\nprediction = prediction.T\nprediction = np.clip(prediction, a_min=0.0, a_max=1.0)\n\nfor i in range(30):\n    sample[target_cols[i]] = prediction[i]\n\n\nsample.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/google-quest-challenge/train.csv\")\ndf[target_cols].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}